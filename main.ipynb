{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import DataExtractor\n",
    "from database_utils import DatabaseConnector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://aicore_admin:***@data-handling-project-readonly.cq2e8zno855e.eu-west-1.rds.amazonaws.com:5432/postgres)\n"
     ]
    }
   ],
   "source": [
    "# Initialize DatabaseConnector\n",
    "db_connector = DatabaseConnector()\n",
    "\n",
    "#read database credentials from YAML file and initialize database engine\n",
    "cred_data = db_connector.read_db_creds()\n",
    "engine = db_connector.init_db_engine(cred_data)\n",
    "print(engine)\n",
    "    \n",
    "#initialize DataExtractor \n",
    "extractor = DataExtractor(engine)\n",
    "\n",
    "#get the names of all tables in the database\n",
    "tables = db_connector.list_db_tables(engine)\n",
    "\n",
    "#loop through each table and extract data into a DataFrame\n",
    "for table_name in tables:\n",
    "    df = extractor.read_rds_table(table_name)\n",
    "    df.to_csv(table_name+'.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United Kingdom    9371\n",
      "Germany           4708\n",
      "United States     1205\n",
      "GMRBOMI0O1           1\n",
      "7ZNO5EBALT           1\n",
      "3518UD5CE8           1\n",
      "RQRB7RMTAD           1\n",
      "PNRMPSYR1J           1\n",
      "5EFAFD0JLI           1\n",
      "YOTSVPRBQ7           1\n",
      "EWE3U0DZIV           1\n",
      "50KUU3PQUF           1\n",
      "XN9NGL5C0B           1\n",
      "S0E37H52ON           1\n",
      "XGI7FM0VBJ           1\n",
      "AJ1ENKS3QL           1\n",
      "I7G4DMDZOZ           1\n",
      "T4WBZSW0XI           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('legacy_users.csv')\n",
    "print(df['country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "from data_cleaning import DataCleaning\n",
    "from data_upload import DataLoader\n",
    "import pandas as pd \n",
    "\n",
    "data_cleaner = DataCleaning()\n",
    "df = pd.read_csv('legacy_users.csv')\n",
    "df = data_cleaner.clean_user_data(df)\n",
    "df = df.reset_index(drop=True)\n",
    "df.drop(df.columns[0:2], axis=1, inplace=True)\n",
    "df.to_csv('dim_users.csv')\n",
    "\n",
    "# Uploading to postgres database \n",
    "db_connector = DatabaseConnector()\n",
    "cred_data = db_connector.read_local_creds()\n",
    "local_engine = db_connector.local_db_engine(cred_data)\n",
    "\n",
    "data_loader = DataLoader(local_engine)\n",
    "data_loader.upload_to_db(df,'dim_users') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing jpype dependencies. Fallback to subprocess.\n",
      "No module named 'jpype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "            card_number expiry_date                card_provider  \\\n",
      "0        30060773296197       09/26  Diners Club / Carte Blanche   \n",
      "1       349624180933183       10/23             American Express   \n",
      "2      3529023891650490       06/23                 JCB 16 digit   \n",
      "3       213142929492281       09/27                 JCB 15 digit   \n",
      "4          502067329974       10/25                      Maestro   \n",
      "...                 ...         ...                          ...   \n",
      "15304   180036921556789       12/28                 JCB 15 digit   \n",
      "15305   180018030448512       11/24                 JCB 15 digit   \n",
      "15306  3569953313547220       04/24                 JCB 16 digit   \n",
      "15307  4444521712606810       06/27                VISA 16 digit   \n",
      "15308   372031786522735       02/30             American Express   \n",
      "\n",
      "      date_payment_confirmed  \n",
      "0                 2015-11-25  \n",
      "1                 2001-06-18  \n",
      "2                 2000-12-26  \n",
      "3                 2011-02-12  \n",
      "4                 1997-03-13  \n",
      "...                      ...  \n",
      "15304             1997-06-06  \n",
      "15305             2004-06-16  \n",
      "15306             2020-02-05  \n",
      "15307             2008-06-16  \n",
      "15308             2009-02-04  \n",
      "\n",
      "[15309 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "link = \"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\"\n",
    "db_connector = DatabaseConnector()\n",
    "cred_data = db_connector.read_db_creds()\n",
    "engine = db_connector.init_db_engine(cred_data)\n",
    "pdf_extractor = DataExtractor(engine)\n",
    "df = pdf_extractor.retrieve_pdf_data(link)\n",
    "print(type(df))\n",
    "print(df)\n",
    "df.to_csv('card_details.csv',index= False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import DataCleaning\n",
    "from data_upload import DataLoader\n",
    "\n",
    "\n",
    "data_cleaner = DataCleaning()\n",
    "df = pd.read_csv('card_details.csv')\n",
    "df = data_cleaner.clean_card_data(df)\n",
    "df.to_csv('dim_card_details.csv')\n",
    "\n",
    "# Uploading to postgres database \n",
    "db_connector = DatabaseConnector()\n",
    "cred_data = db_connector.read_local_creds()\n",
    "local_engine = db_connector.local_db_engine(cred_data)\n",
    "\n",
    "data_loader = DataLoader(local_engine)\n",
    "data_loader.upload_to_db(df,'dim_card_details') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: The store data is retrieved through the use of an API.\n",
    "\n",
    "The API has two GET methods. One will return the number of stores in the business and the other to retrieve a store given a store number.\n",
    "\n",
    "A dictionary stores the header details it will have a key x-api-key with the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'statusCode': 200, 'number_stores': 451}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'address': 'Heckerstraße 4/5\\n50491 Säckingen, Landshut',\n",
       " 'longitude': '48.52961',\n",
       " 'lat': None,\n",
       " 'locality': 'Landshut',\n",
       " 'store_code': 'LA-0772C7B9',\n",
       " 'staff_numbers': '92',\n",
       " 'opening_date': '2013-04-12',\n",
       " 'store_type': 'Super Store',\n",
       " 'latitude': '12.16179',\n",
       " 'country_code': 'DE',\n",
       " 'continent': 'Europe'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The store data can be retrieved through the use of an API.\n",
    "from data_extraction import DataExtractor\n",
    "\n",
    "header_dict = {'x-api-key' : 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "store_retrieve = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/2'\n",
    "storenum_endp= 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "data_extractor = DataExtractor(engine) # engine being problematic?!?!?!?!?!\n",
    "data_extractor.list_number_of_stores(storenum_endp,header_dict)\n",
    "data_extractor.retrieve_stores_data(store_retrieve,header_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5.3: Outputs the API extracted data to a DataFrame then CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range (0,451):\n",
    "    store_data = data_extractor.retrieve_stores_data(f'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{i}',header_dict)\n",
    "    rows.append(store_data)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('stores_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_type\n",
       "Local          255\n",
       "Super Store     89\n",
       "Mall Kiosk      51\n",
       "Outlet          45\n",
       "NULL             3\n",
       "Web Portal       1\n",
       "QP74AHEQT0       1\n",
       "O0QJIRC943       1\n",
       "50IB01SFAZ       1\n",
       "0RSNUU3DF5       1\n",
       "B4KVQB3P5Y       1\n",
       "X0FE7E2EOG       1\n",
       "NN04B3F6UQ       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['store_type'].value_counts()\n",
    "store_types = ['Local','Super Store','Mall Kiosk','Outlet','Web Portal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 451 entries, 0 to 450\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          451 non-null    int64 \n",
      " 1   address        451 non-null    object\n",
      " 2   longitude      451 non-null    object\n",
      " 3   lat            11 non-null     object\n",
      " 4   locality       451 non-null    object\n",
      " 5   store_code     451 non-null    object\n",
      " 6   staff_numbers  451 non-null    object\n",
      " 7   opening_date   451 non-null    object\n",
      " 8   store_type     451 non-null    object\n",
      " 9   latitude       450 non-null    object\n",
      " 10  country_code   451 non-null    object\n",
      " 11  continent      451 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 42.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 423 entries, 0 to 422\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   address        423 non-null    object        \n",
      " 1   longitude      423 non-null    float64       \n",
      " 2   locality       423 non-null    object        \n",
      " 3   store_code     423 non-null    object        \n",
      " 4   staff_numbers  423 non-null    float64       \n",
      " 5   opening_date   423 non-null    datetime64[ns]\n",
      " 6   store_type     423 non-null    object        \n",
      " 7   latitude       423 non-null    float64       \n",
      " 8   country_code   423 non-null    object        \n",
      " 9   continent      423 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(6)\n",
      "memory usage: 33.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from data_cleaning import DataCleaning\n",
    "from database_utils import DatabaseConnector\n",
    "from data_upload import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_cleaner = DataCleaning()\n",
    "df = pd.read_csv('stores_data.csv')\n",
    "df = data_cleaner.clean_store_data(df)\n",
    "df = df.reset_index(drop=True)\n",
    "df.drop(df.columns[0:2], axis=1, inplace=True)\n",
    "df.to_csv('dim_store_details.csv')\n",
    "df.info()\n",
    "# Uploading to postgres database \n",
    "db_connector = DatabaseConnector()\n",
    "cred_data = db_connector.read_local_creds()\n",
    "local_engine = db_connector.local_db_engine(cred_data)\n",
    "\n",
    "data_loader = DataLoader(local_engine)\n",
    "data_loader.upload_to_db(df,'dim_store_details') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
